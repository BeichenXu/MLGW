{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX devices:[CpuDevice(id=0)]\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import optax\n",
    "import flax\n",
    "from flax.training.train_state import TrainState\n",
    "from functools import partial\n",
    "from tqdm.auto import tqdm\n",
    "from dataset.toytext import TextDataset\n",
    "from models.language import BigramLM, TransormerLM, MambaLM\n",
    "import training\n",
    "\n",
    "print(f\"JAX devices:{jax.devices()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_key = jax.random.key(0)\n",
    "max_context_len = 32\n",
    "batch_size = 32\n",
    "\n",
    "dataset = TextDataset(data_path=\"dataset/shakespeare.txt\")\n",
    "# model = MambaLM(\n",
    "#     vocab_size=len(dataset.tokenizer.vocab),\n",
    "#     max_context_len=max_context_len,\n",
    "#     embedding_dim=64,\n",
    "#     state_dim=128,\n",
    "#     n_layers=8\n",
    "# )\n",
    "model= TransormerLM(\n",
    "    vocab_size=len(dataset.tokenizer.vocab),\n",
    "    max_context_len=max_context_len,\n",
    "    embedding_dim=64,\n",
    "    head_size=128,\n",
    "    n_heads=4,\n",
    "    n_layers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b2877284f614e359c7651fe34921234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd6182f9826d458cb8b47e00d57b0043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.6292376518249512\n",
      "Generation test: \n",
      "\u001b[94m First Citizen:\n",
      "Before we proceed \u001b[0m\n",
      "As that never his man? By passand-comie?\n",
      "\n",
      "ROMEO:\n",
      "You, if I saddly made mup of the Vousician cisome."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94881ce014c44e7827b9c9243a94a47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.4245597124099731\n",
      "Generation test: \n",
      "\u001b[94m First Citizen:\n",
      "Before we proceed \u001b[0m\n",
      "me that news on: both you piece\n",
      "is thine acquits high.\n",
      "\n",
      "PRINCE EDWARD:\n",
      "Now will as you were the man"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db61cdae6a4041e589db38a2ce50a69a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.381343126296997\n",
      "Generation test: \n",
      "\u001b[94m First Citizen:\n",
      "Before we proceed \u001b[0m\n",
      "me that never his offence of face,\n",
      "And much, his hands; teach within this to his straight\n",
      "Whose man"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa828b6a4cba49a1bb30f962209035ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.3584356307983398\n",
      "Generation test: \n",
      "\u001b[94m First Citizen:\n",
      "Before we proceed \u001b[0m\n",
      "Like an one excuse?\n",
      "\n",
      "HUMBEN Scarisor! yet concever.\n",
      "\n",
      "YORK:\n",
      "No crack at lupt the air discour cisomed"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "928ab5b999ab41d99d74ece4cdfa325f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.3407204151153564\n",
      "Generation test: \n",
      "\u001b[94m First Citizen:\n",
      "Before we proceed \u001b[0m\n",
      "me that need on: but what pleft\n",
      "is this?\n",
      "\n",
      "ROMEO:\n",
      "You are not danger deposed; he's the prince\n",
      "Were b"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a8185b7c9fc484083b1101e923c6c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.3261581659317017\n",
      "Generation test: \n",
      "\u001b[94m First Citizen:\n",
      "Before we proceed \u001b[0m\n",
      "Let the neck once of what piece is thine\n",
      "A quake thing; that doth made me to his eye.\n",
      "\n",
      "MENENIUS:\n",
      "Bi"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "849a062f30354950a30be4bd7210a73e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.3162202835083008\n",
      "Generation test: \n",
      "\u001b[94m First Citizen:\n",
      "Before we proceed \u001b[0mings take my excius?\n",
      "\n",
      "DUKE OF YORK:\n",
      "No, my conjicience into thy case and rotes\n",
      "Of stidon'd and some "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e4749551f3044948168a3bd5332930f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.3063478469848633\n",
      "Generation test: \n",
      "\u001b[94m First Citizen:\n",
      "Before we proceed \u001b[0m\n",
      "Let the netter-missed hate; but in this day, his hands;\n",
      "that docting the prosperous dream\n",
      "With Clar"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e4c3afbcd2427ca211faa54b57a0c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.2990070581436157\n",
      "Generation test: \n",
      "\u001b[94m First Citizen:\n",
      "Before we proceed \u001b[0m\n",
      "Lest and my executol laid possesses.\n",
      "\n",
      "Third Servant:\n",
      "You say done?\n",
      "\n",
      "ANGELO:\n",
      "O that you were costman"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e8177558ca04c4eb84baa74e8aba62c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.2919578552246094\n",
      "Generation test: \n",
      "\u001b[94m First Citizen:\n",
      "Before we proceed \u001b[0m\n",
      "Lest and my exhile?\n",
      "\n",
      "HURTIUS:\n",
      "Come to your daughter for tears with many thousand sticks light.\n",
      "Clam"
     ]
    }
   ],
   "source": [
    "optimization_step = jax.jit(\n",
    "    partial(training.optimization_step, loss_fn=training.logit_prediction_loss)\n",
    ")\n",
    "get_batch = jax.jit(dataset.get_batch, static_argnames=[\"batch_size\", \"context_len\"])\n",
    "generate_token = jax.jit(partial(model.apply, method=model.generate_token))\n",
    "\n",
    "def generate_text(params, prompt: str, length=100, rng_key=jax.random.key(0)):\n",
    "    context = dataset.tokenizer.encode(prompt)\n",
    "    print(\"\\033[94m\", dataset.tokenizer.decode(context), \"\\033[0m\", end=\"\")\n",
    "    for sub_rng in jax.random.split(rng_key, length):\n",
    "        next_token, context = generate_token(params, context, sub_rng)\n",
    "        print(dataset.tokenizer.decode(next_token[None]), end=\"\")\n",
    "\n",
    "\n",
    "train_state = TrainState.create(\n",
    "    apply_fn=model.apply,\n",
    "    params=model.init(rng_key, dataset.sample(max_context_len, rng_key)),\n",
    "    tx=optax.chain(optax.clip(1.0), optax.adam(1e-3, b2=0.95)),\n",
    ")\n",
    "\n",
    "N_epochs = 10\n",
    "batches_per_epoch = 10000\n",
    "for epoch_idx, epoch_rng_key in tqdm(enumerate(jax.random.split(rng_key, N_epochs))):\n",
    "    losses = []\n",
    "    for batch_rng_key in tqdm(jax.random.split(epoch_rng_key, batches_per_epoch), leave=False):\n",
    "        x, y = get_batch(batch_size, max_context_len, rng_key=batch_rng_key)\n",
    "        train_state, loss_value = optimization_step(train_state, x, y)\n",
    "        losses.append(loss_value)\n",
    "    print(f\"Loss: {sum(losses) / len(losses)}\\nGeneration test:\")\n",
    "    generate_text(train_state.params, prompt=dataset.fulltext[:max_context_len], rng_key=rng_key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
