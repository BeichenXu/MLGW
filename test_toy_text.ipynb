{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX devices:[CpuDevice(id=0)]\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import optax\n",
    "import flax\n",
    "from flax.training.train_state import TrainState\n",
    "from functools import partial\n",
    "from tqdm.auto import tqdm\n",
    "from dataset.toytext import TextDataset\n",
    "from models.language import BigramLM, TransormerLM, MambaLM\n",
    "import training\n",
    "\n",
    "print(f\"JAX devices:{jax.devices()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_key = jax.random.key(0)\n",
    "max_context_len = 32\n",
    "batch_size = 32\n",
    "\n",
    "dataset = TextDataset(data_path=\"dataset/shakespeare.txt\")\n",
    "model = MambaLM(\n",
    "    vocab_size=len(dataset.tokenizer.vocab),\n",
    "    max_context_len=max_context_len,\n",
    "    embedding_dim=64,\n",
    "    state_dim=128,\n",
    "    n_layers=2\n",
    ")\n",
    "# model= TransormerLM(\n",
    "#     vocab_size=len(dataset.tokenizer.vocab),\n",
    "#     max_context_len=max_context_len,\n",
    "#     embedding_dim=64,\n",
    "#     head_size=128,\n",
    "#     n_heads=4,\n",
    "#     n_layers=4\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4b3f758e03d4df79cf42b56f5bc10eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f73f239e64694c9dbb86a1a9f0ffee52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimization_step = jax.jit(\n",
    "    partial(training.optimization_step, loss_fn=training.logit_prediction_loss)\n",
    ")\n",
    "get_batch = jax.jit(dataset.get_batch, static_argnames=[\"batch_size\", \"context_len\"])\n",
    "generate_token = jax.jit(partial(model.apply, method=model.generate_token))\n",
    "\n",
    "def generate_text(params, prompt: str, length=100, rng_key=jax.random.key(0)):\n",
    "    context = dataset.tokenizer.encode(prompt)\n",
    "    print(\"\\033[94m\", dataset.tokenizer.decode(context), \"\\033[0m\", end=\"\")\n",
    "    for sub_rng in jax.random.split(rng_key, length):\n",
    "        next_token, context = generate_token(params, context, sub_rng)\n",
    "        print(dataset.tokenizer.decode(next_token[None]), end=\"\")\n",
    "\n",
    "\n",
    "train_state = TrainState.create(\n",
    "    apply_fn=model.apply,\n",
    "    params=model.init(rng_key, dataset.sample(max_context_len, rng_key)),\n",
    "    tx=optax.chain(optax.clip(1.0), optax.adam(1e-3, b2=0.95)),\n",
    ")\n",
    "\n",
    "N_epochs = 10\n",
    "batches_per_epoch = 1000\n",
    "for epoch_idx, epoch_rng_key in tqdm(enumerate(jax.random.split(rng_key, N_epochs))):\n",
    "    losses = []\n",
    "    for batch_rng_key in tqdm(jax.random.split(epoch_rng_key, batches_per_epoch), leave=False):\n",
    "        x, y = get_batch(batch_size, max_context_len, rng_key=batch_rng_key)\n",
    "        train_state, loss_value = optimization_step(train_state, x, y)\n",
    "        losses.append(loss_value)\n",
    "    print(f\"Loss: {sum(losses) / len(losses)}\\nGeneration test: \")\n",
    "    generate_text(train_state.params, prompt=dataset.fulltext[:max_context_len], rng_key=rng_key)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
